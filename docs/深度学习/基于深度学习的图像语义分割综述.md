---
title: "基于深度学习的图像语义分割方法研究综述"
---

#### 作者
**曾文献、马月、丁宇、张淑青、李伟光** 于 **2021** 年发表于期刊 **现代计算机**


## 分类

### 根据数据标注类型和网络学习方式的不同

- 基于全监督学习的方法
- 基于弱监督学习的方法
- 基于自监督学习的方法


### 常用的深度学习语义分割网络

- 卷积神经网络 CNN (Convolutional Neural Network)
- 全卷积网络 FCN (Fully Convolutional Network)
- 循环神经网络 RNN (Recurrent Neural Network)
- 对抗神经网络 GAN (Generative Adversarial Network)


## 基于全监督学习的语义分割方法

### 基于改进的 FCN 的方法

FCN 是将卷积神经网络最后一层的全连接层替换成 1×1 的卷积层，然后通过反卷积层对最后一个卷积层进行上采样，使输出恢复到输入图像相同的尺寸，最后每个像素进行预测。

- 局限性
    - 虽然上采样恢复了图像的尺寸，但丢失了部分像素的位置信息
    - FCN 没有考虑全局上下文的信息，缺乏空间的一致性

#### 感受野

- [参考文章](https://blog.csdn.net/program_developer/article/details/80958716)
- 在卷积神经网络中，感受野（Receptive Field）的定义是卷积神经网络每一层输出的特征图（feature map）上的像素点在输入图片上映射的区域大小。再通俗点的解释是，特征图上的一个点对应输入图上的区域
<div align="center"><img src="./pictures/基于深度学习的图像语义分割方法综述/001_感受野的概念.png" width="60%"/></div> 

- 两层 3\*3 的卷积核卷积操作之后的感受野是5\*5，三层3\*3卷积核操作之后的感受野是7\*7，其中卷积核（filter）的步长（stride）为1、padding为0。

- **感受野的计算**
    - 最后一层（卷积层或池化层）输出特征图感受野的大小等于卷积核的大小。
    - 第 $i$ 层卷积层的感受野大小和第 $i$ 层的卷积核大小和步长有关系，同时也与第 $(i+1)$ 层感受野大小有关。
    - 计算感受野的大小时忽略了图像边缘的影响，即不考虑 $padding$ 的大小。
    - 关于感受野大小的计算方式是采用从最后一层往下计算的方法，即先计算最深层在前一层上的感受野，然后逐层传递到第一层，使用的公式可以表示如下：  
<div align="center">$RF_i=(RF_{i+1}-1)×stride_i+Ksize_i$</div>
其中，$RF_i$ 是第 $i$ 层卷积层的感受野，$RF_{i+1}$ 是第 $i+1$ 层上的感受野，$stride_i$ 是卷积的步长，$Ksize_i$ 是本层卷积核的大小。

#### 基于空洞卷积的方法

- **优势**  
可在不减小图像大小的情况下增大感受野提高图像特征图的分辨率

- **DeepLab 深度卷积网络模型**  
    - 利用 **空洞卷积** 代替反卷积操作来增加感受野，获得更多的上下文信息
    - 增加了 **条件随机场CRF** (Conditional Random Field)以提高网络语义分割的准确性
